{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bb = bounding box\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Section of bounding boxes operations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def scale_bb(x, y, w, h, max_x, max_y, scale):\n",
    "    \n",
    "    # returns scaled parameters of the bounding box\n",
    "    \n",
    "    return [\n",
    "            int(x - w * (scale - 1)/2), \n",
    "            int(y - h * (scale - 1)/2), \n",
    "            int(w * (scale)),\n",
    "            int(h * (scale))\n",
    "            ]\n",
    "\n",
    "def intersection_area(x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "    x11 = x1\n",
    "    x21 = x2\n",
    "    x12 = x1 + w1\n",
    "    x22 = x2 + w2\n",
    "    y11 = y1\n",
    "    y21 = y2\n",
    "    y12 = y1 + h1\n",
    "    y22 = y2 + h2\n",
    "    x_overlap = max(0, min(x12,x22) - max(x11,x21));\n",
    "    y_overlap = max(0, min(y12,y22) - max(y11,y21));\n",
    "    overlapArea = x_overlap * y_overlap;\n",
    "    return overlapArea\n",
    "\n",
    "def square(bb):\n",
    "    \n",
    "    # count bb square\n",
    "    \n",
    "    return bb[2] * bb[3]\n",
    "\n",
    "def intersection_square(bb1, bb2):\n",
    "    \n",
    "    # count square of intersection\n",
    "    \n",
    "    x_left_bound = sorted([bb1[0], bb2[0]])\n",
    "    x_right_bound = sorted([bb1[0] + bb1[2], bb2[0] + bb2[2]])\n",
    "    y_lower_bound = sorted([bb1[1], bb2[1]])\n",
    "    y_upper_bound = sorted([bb1[1] + bb1[3], bb2[1] + bb2[3]])\n",
    "    return (x_right_bound[0] - x_left_bound[1]) * (y_upper_bound[0] - y_lower_bound[1])\n",
    "\n",
    "def have_intersection(bb1, bb2):\n",
    "    \n",
    "    # check if two bounding boxes have an intersection\n",
    "    \n",
    "    return not (bb1[0] + bb1[2] < bb2[0] \n",
    "                or bb2[0] + bb2[2] < bb1[0] \n",
    "                or bb1[1] + bb1[3] < bb2[1] \n",
    "                or bb2[1] + bb2[3] < bb1[1])\n",
    "\n",
    "\n",
    "def pts_to_bb(pts):\n",
    "    x = min(pts[0][0], pts[1][0], pts[2][0], pts[3][0]) \n",
    "    y = min(pts[0][1], pts[1][1], pts[2][1], pts[3][1]) \n",
    "    w = max(pts[0][0], pts[1][0], pts[2][0], pts[3][0]) - x\n",
    "    h = max(pts[0][1], pts[1][1], pts[2][1], pts[3][1]) - y\n",
    "    return [x, y, w, h]\n",
    "\n",
    "\n",
    "def detect_faces(img, detector):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return detector.detectMultiScale(gray, 1.1, 3) # DO NOT CHANGE PARAMETERS  1.099, 0\n",
    "\n",
    "def filter_bbs(bbs, max_w, max_h):\n",
    "    res = []\n",
    "    for [x, y, w, h] in bbs:\n",
    "        bbs_inside_count = 0\n",
    "        good = 1\n",
    "        \n",
    "        for [x2, y2, w2, h2] in bbs:\n",
    "            if w > max_w / 7.0 or h > max_h / 7.0:\n",
    "                good = 0\n",
    "                break\n",
    "            if [x, y, w, h] != [x2, y2, w2, h2] and have_intersection([x, y, w, h], [x2, y2, w2, h2]):\n",
    "                area = intersection_area(x, y, w, h, x2, y2, w2, h2)\n",
    "                if float(area) / (w2*h2) > 0.8:\n",
    "                    bbs_inside_count += 1\n",
    "#                 elif area != w*h:\n",
    "#                     if area / w2*h2 > 0.9 and area / w*h > 0.5:\n",
    "#                         good = 0\n",
    "#                         break\n",
    "                if (bbs_inside_count > 1):\n",
    "                    good = 0\n",
    "                    break\n",
    "        if good:\n",
    "            res.append(np.array([x, y, w, h]))\n",
    "        \n",
    "    return np.array(res)\n",
    "                       \n",
    "def check_bb_for_face(bb, img, detector=\"VJ\"):\n",
    "    crop = img[bb[1]:bb[1] + bb[3], bb[0]:bb[0] + bb[2]]\n",
    "    if detector == \"dlib\":\n",
    "        dlib_detector = dlib.get_frontal_face_detector()\n",
    "        detections = dlib_detector(crop, 1)\n",
    "        for k,d in enumerate(detections):\n",
    "            return True\n",
    "        return False\n",
    "    if detector == \"VJ\":\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        bbs = face_cascade.detectMultiScale(gray, 1.099, 0)\n",
    "        if len(bbs):\n",
    "            return True\n",
    "        return False\n",
    "    if detector == \"cnn\":\n",
    "        prediction = Net.predict([crop],oversample=False)\n",
    "        if (prediction[0][0] > 0.8) or (prediction[0][1] > 0.8):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "def preprocess_embbedings(bbs):\n",
    "\n",
    "#     returns only those bbs which do not contain more than 1 embbeding bb\n",
    "\n",
    "    class Collision:\n",
    "\n",
    "#     Class to store overlapings and embeddings for a bounding box\n",
    "\n",
    "        def __init__(self, bb_id, overlap_ids=[], embedding_ids=[]):\n",
    "            self.id = bb_id\n",
    "            self.overlaps = overlap_ids\n",
    "            self.embeddings = embedding_ids\n",
    "\n",
    "\n",
    "    bbs_sorted = sorted(bbs, key = lambda bb: bb[0])\n",
    "\n",
    "    collisions = []\n",
    "    for bb_id in range(len(bbs_sorted)):\n",
    "        overlap_ids = []\n",
    "        embedding_ids = []\n",
    "        for bb_other_id in range(bb_id + 1, len(bbs_sorted)):\n",
    "            bb_right = bbs_sorted[bb_id][0] + bbs_sorted[bb_id][2]\n",
    "            if bbs_sorted[bb_other_id][0] > bb_right:\n",
    "                break\n",
    "            if bbs_sorted[bb_other_id][0] + bbs_sorted[bb_other_id][2] < bb_right:\n",
    "                if have_intersection(bbs_sorted[bb_other_id], bbs_sorted[bb_id]):\n",
    "                    embedding_ids.append(bb_other_id)\n",
    "            else:\n",
    "                if have_intersection(bbs_sorted[bb_other_id], bbs_sorted[bb_id]):\n",
    "                    intersect_square = intersection_square(bbs_sorted[bb_other_id], bbs_sorted[bb_id])\n",
    "                    if intersect_square > 0.3 * max(square(bbs_sorted[bb_other_id]), square(bbs_sorted[bb_id])):\n",
    "                        overlap_ids.append(bb_other_id)\n",
    "        collisions.append(Collision(bb_id, overlap_ids, embedding_ids))\n",
    "\n",
    "    ids_to_remove = []\n",
    "    for bb in collisions:\n",
    "        if len(bb.embeddings) >= 1:\n",
    "            ids_to_remove.append(bb.id)\n",
    "        if len(bb.overlaps) > 0:\n",
    "            id_to_save = max(bb.overlaps, key=lambda id: square(bbs_sorted[id]))\n",
    "            ids_to_remove.extend([id for id in bb.overlaps if id != id_to_save])\n",
    "\n",
    "    new_bbs = [bbs_sorted[i] for i in range(len(bbs_sorted)) if i not in ids_to_remove]\n",
    "    \n",
    "    return new_bbs    \n",
    "\n",
    "def get_bbs(img, detector):\n",
    "    \n",
    "    # returns all found faces coordinates on the image\n",
    "    bbs = detect_faces(img, detector)\n",
    "#     filtered = preprocess_embbedings(bbs)\n",
    "#     checked = [bb for bb in filtered if check_bb_for_face(bb, img)]\n",
    "#     return np.array(checked)\n",
    "    return bbs\n",
    "\n",
    "\n",
    "def are_close(bb1, bb2):\n",
    "    \n",
    "    # check if two bounding boxes are close and have similar shapes\n",
    "    \n",
    "    if abs(bb1[2]*bb1[3] - bb2[2]*bb2[3]) > max(bb1[2]*bb1[3], bb2[2]*bb2[3]) / 4:\n",
    "        return False\n",
    "    \n",
    "    return (abs(bb1[0] + bb1[2] / 2 - bb2[0] - bb2[2] / 2) < bb1[2] / 2) and \\\n",
    "            (abs(bb1[1] + bb1[3] / 2 - bb2[1] - bb2[3] / 2) <  bb1[3] / 2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Editing found faces\n",
    "\n",
    "\"\"\"    \n",
    "def track_obj(face, frame):\n",
    "    track_window = face\n",
    "    (x, y, w, h) = face\n",
    "    (x, y, w, h) = (int(max(0, x)), int(max(0, y)), int(max(0, w)), int(max(0, h)))\n",
    "#     x = int(min(frame.shape[0], x))\n",
    "#     y = int(min(frame.shape[1], y))\n",
    "#     w = int(min(frame.shape[0] - x, w))\n",
    "#     h = int(min(frame.shape[1] - y, h)) \n",
    "#     print (x, y, w, h)               \n",
    "    roi = frame[y:y + h, x:x + w]\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_roi, np.array((0., 51., 89.)), np.array((17., 140., 255.)))\n",
    "    roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "    cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    return track_window, roi, hsv_roi, mask, roi_hist, term_crit    \n",
    "\n",
    "\n",
    "\n",
    "def preprocess_bbs(bbs, frames_arr, timeout=100, im_width=800, im_height=400):\n",
    "    \n",
    "    # returns improved bounding boxes with person_id\n",
    "    \n",
    "    \n",
    "    faces = {} # faces dict before proccessing\n",
    "    max_id = 1\n",
    "    \n",
    "    for fn in bbs:\n",
    "        faces[fn] = {}\n",
    "        for bb in bbs[fn]:\n",
    "            faces[fn][max_id] = {}\n",
    "            faces[fn][max_id]['timeout'] = timeout\n",
    "            faces[fn][max_id]['coords'] = scale_bb(bb[0], bb[1], bb[2], bb[3], im_width, im_height, 1)\n",
    "            max_id += 1\n",
    "            \n",
    "    \n",
    "    new_faces = {} # faces dict after proccessing\n",
    "    \n",
    "    new_faces[0] = faces[0]\n",
    "         \n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 100,\n",
    "                           qualityLevel = 0.3,\n",
    "                           minDistance = 7,\n",
    "                           blockSize = 7 )\n",
    "    \n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    opt_flow_dict = {}\n",
    "    mean_shift_dict = {}\n",
    "    \n",
    "    detection_cell = 1\n",
    "    \n",
    "    for frame in faces:\n",
    "        if frame != 0:\n",
    "            new_faces[frame] = {} \n",
    "            \n",
    "            # update detected faces\n",
    "            \n",
    "            if frame % detection_cell == 0: # detect faces each detection_cell frame\n",
    "                for cur_id in faces[frame]:\n",
    "                    found = 0\n",
    "                    intersect = 0\n",
    "                    for prev_id in new_faces[frame - 1]:          \n",
    "                        if (have_intersection(new_faces[frame - 1][prev_id]['coords'], \n",
    "                                              faces[frame][cur_id]['coords'])):\n",
    "                            intersect = 1\n",
    "\n",
    "                        if new_faces[frame - 1][prev_id]['timeout'] > 0:\n",
    "                            if not found and are_close(new_faces[frame - 1][prev_id]['coords'], \n",
    "                                                       faces[frame][cur_id]['coords']):\n",
    "                                \n",
    "                                new_faces[frame][prev_id] = new_faces[frame-1][prev_id].copy()\n",
    "                                new_faces[frame - 1][prev_id]['timeout'] = -1\n",
    "                                new_faces[frame][prev_id]['timeout'] = timeout\n",
    "                                found = 1\n",
    "                                \n",
    "                                \n",
    "#                                 if prev_id  in mean_shift_dict:\n",
    "                                    # track this face for meanshift\n",
    "\n",
    "                                track_windows, rois, hsv_rois, masks, roi_hists, term_crit = \\\n",
    "                                        track_obj(new_faces[frame][prev_id]['coords'], frames_arr[frame])\n",
    "                                mean_shift_dict[prev_id] = [track_windows, roi_hists]\n",
    "\n",
    "                                # track this face for optical flow\n",
    "\n",
    "                                (x, y, h, w) = new_faces[frame][prev_id]['coords']\n",
    "\n",
    "                                old_gray = cv2.cvtColor(frames_arr[frame], cv2.COLOR_BGR2GRAY)                \n",
    "                                mask = np.zeros_like(old_gray)\n",
    "                                mask[y:y+h, x:x+w] = 1\n",
    "                                p0 = cv2.goodFeaturesToTrack(old_gray, mask = mask, **feature_params)\n",
    "                                opt_flow_dict[prev_id] = [old_gray, p0]\n",
    "                                \n",
    "\n",
    "                    if not found and not intersect: \n",
    "                        # insert new face which was not detected before\n",
    "                        \n",
    "                        new_faces[frame][cur_id] = faces[frame][cur_id]\n",
    "                        \n",
    "                        # track this face for meanshift\n",
    "                        \n",
    "                        track_windows, rois, hsv_rois, masks, roi_hists, term_crit = \\\n",
    "                                track_obj(new_faces[frame][cur_id]['coords'], frames_arr[frame])\n",
    "                        mean_shift_dict[cur_id] = [track_windows, roi_hists]\n",
    "                        \n",
    "                        # track this face for optical flow\n",
    "                        \n",
    "                        (x, y, h, w) = new_faces[frame][cur_id]['coords']\n",
    "                        \n",
    "                        old_gray = cv2.cvtColor(frames_arr[frame], cv2.COLOR_BGR2GRAY)                \n",
    "                        mask = np.zeros_like(old_gray)\n",
    "                        mask[y:y+h, x:x+w] = 1\n",
    "                        p0 = cv2.goodFeaturesToTrack(old_gray, mask = mask, **feature_params)\n",
    "                        opt_flow_dict[cur_id] = [old_gray, p0]\n",
    "               \n",
    "            # update lost faces from previous frame\n",
    "            \n",
    "            for prev_id in new_faces[frame - 1]:\n",
    "                if new_faces[frame - 1][prev_id]['timeout'] > 0:\n",
    "                    new_faces[frame - 1][prev_id]['timeout'] -= 1\n",
    "                    \n",
    "                    if not prev_id in opt_flow_dict: # start tracking\n",
    "                        \n",
    "                        # MEANSHIFT\n",
    "                        \n",
    "                        track_windows, rois, hsv_rois, masks, roi_hists, term_crit = \\\n",
    "                            track_obj(new_faces[frame - 1][prev_id]['coords'], frames_arr[frame-1])\n",
    "                        \n",
    "                        mean_shift_dict[prev_id] = [track_windows, roi_hists]\n",
    "                        \n",
    "                        # OPTICAL FLOW\n",
    "                        \n",
    "                        (x, y, h, w) = new_faces[frame - 1][prev_id]['coords']\n",
    "                        \n",
    "                        (x, y, h, w) = scale_bb(x, y, h, w, frames_arr[frame - 1].shape[0], \n",
    "                                                frames_arr[frame - 1].shape[1], 1)\n",
    "                        \n",
    "                        old_gray = cv2.cvtColor(frames_arr[frame - 1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        mask = np.zeros_like(old_gray)         \n",
    "                        mask[y:y+h, x:x+w] = 1\n",
    "\n",
    "                        p0 = cv2.goodFeaturesToTrack(old_gray, mask = mask, **feature_params)\n",
    "                        \n",
    "                        opt_flow_dict[prev_id] = [old_gray, p0]\n",
    "                        \n",
    "                        # update bb\n",
    "                        new_faces[frame][prev_id] = new_faces[frame - 1][prev_id].copy()\n",
    "                        \n",
    "                    \n",
    "                    else: # continue tracking\n",
    "                        \n",
    "                        # OPTICAL FLOW\n",
    "                        \n",
    "                        (x0, y0, h0, w0) = new_faces[frame - 1][prev_id]['coords']\n",
    "                        \n",
    "                        p0 = opt_flow_dict[prev_id][1]\n",
    "                        \n",
    "                        count = 0\n",
    "                        \n",
    "#                         (x, y, h, w) = (0,0,0,0)\n",
    "                        \n",
    "                        if not p0 is None:\n",
    "                            \n",
    "                            old_coords = new_faces[frame - 1][prev_id]['coords']\n",
    "                            \n",
    "                            old_gray = opt_flow_dict[prev_id][0]\n",
    "\n",
    "                            frame_gray = cv2.cvtColor(frames_arr[frame], cv2.COLOR_BGR2GRAY)\n",
    "                            \n",
    "                            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "                            p0r, st, err = cv2.calcOpticalFlowPyrLK(frame_gray, old_gray, p1, None, **lk_params)\n",
    "                            \n",
    "                            cond = abs(p0-p0r).max(-1) < 1\n",
    "                            \n",
    "                            new_tracks = []\n",
    "                            track_points_limit = 5\n",
    "                            \n",
    "                            for tr, (x, y), good_flag in zip(p0, p1.reshape(-1, 2), cond):\n",
    "                                if not good_flag:\n",
    "                                    continue\n",
    "                                    \n",
    "                                new_tracks.append(np.array([x, y]))\n",
    "\n",
    "                                if len(new_tracks) > track_points_limit:\n",
    "                                    del new_tracks[0]\n",
    "#                                     del new_tracks[1]\n",
    "                              \n",
    "#                                 new_tracks.append(tr[0])\n",
    "                            \n",
    "#                             opt_flow_dict[prev_id][1] = new_tracks.copy()\n",
    "   \n",
    "                            center_m = []\n",
    "                            for z in new_tracks:\n",
    "#                                 print z\n",
    "                                center_m.append(z)\n",
    "                            \n",
    "#                             print center_m\n",
    "                            center_m = np.mean(np.array(center_m), axis=0)\n",
    "#                             print center_m\n",
    "                            if type(center_m) is not np.float64:\n",
    "                                (x, y, w, h) = (int(center_m[0]-w0/2), \n",
    "                                                int(center_m[1]-h0/2), w0, h0)\n",
    "                                \n",
    "                            count = len(new_tracks)\n",
    "          \n",
    "                        if count != 0:\n",
    "                        \n",
    "                            # create new bb coordinates for optical flow from good_new\n",
    "                            \n",
    "                            old_gray = frame_gray.copy()\n",
    "                            p0 = np.array(new_tracks).reshape(-1,1,2)\n",
    "                            opt_flow_dict[prev_id] = [old_gray, p0]\n",
    "                            \n",
    "                        else:\n",
    "                            (x, y, h, w) = new_faces[frame - 1][prev_id]['coords']\n",
    "                        \n",
    "                            (x, y, h, w) = scale_bb(x, y, h, w, frames_arr[frame - 1].shape[0], \n",
    "                                                    frames_arr[frame - 1].shape[1], 1)\n",
    "\n",
    "                            old_gray = cv2.cvtColor(frames_arr[frame - 1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                            mask = np.zeros_like(old_gray)         \n",
    "                            mask[y:y+h, x:x+w] = 1\n",
    "\n",
    "                            p0 = cv2.goodFeaturesToTrack(old_gray, mask = mask, **feature_params)\n",
    "\n",
    "                            opt_flow_dict[prev_id] = [old_gray, p0]\n",
    "\n",
    "                            # update bb\n",
    "                            new_faces[frame][prev_id] = new_faces[frame - 1][prev_id].copy()\n",
    "                        \n",
    "                        # MEANSHIFT\n",
    "#                         print (x, y, h, w)\n",
    "                        hsv = cv2.cvtColor(frames_arr[frame], cv2.COLOR_BGR2HSV)\n",
    "                        dst = cv2.calcBackProject([hsv], [0], mean_shift_dict[prev_id][1], [0, 180], 1)\n",
    "                        ret, mean_shift_dict[prev_id][0] = cv2.meanShift(dst, \n",
    "                                                                         tuple(mean_shift_dict[prev_id][0]), \n",
    "                                                                         term_crit)\n",
    "                        (x2, y2, w2, h2) = mean_shift_dict[prev_id][0]\n",
    "                        if count == 0:\n",
    "                             (x, y, h, w) = (x2, y2, w2, h2)\n",
    "                        # update tracking dict\n",
    "                        \n",
    "                        new_faces[frame][prev_id] = new_faces[frame - 1][prev_id].copy()\n",
    "                        \n",
    "                        # (x, y, w, h) - результаты optflow\n",
    "                        # (x2, y2, w2, h2) - результаты meanshift\n",
    "                        # я беру от них взвешенное среднее и сохраняю как новую рамку\n",
    "                        \n",
    "                        optflow_weight = 1.0\n",
    "                        msh_weight = 1 - optflow_weight\n",
    "                        \n",
    "                        \n",
    "                        new_faces[frame][prev_id]['coords'] = (int(x*optflow_weight + x2*msh_weight), \\\n",
    "                                                               int(y*optflow_weight + y2*msh_weight), \\\n",
    "                                                               int(w*optflow_weight + w2*msh_weight), \\\n",
    "                                                               int(h*optflow_weight + h2*msh_weight))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    return new_faces\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Section of reading, drawing and writing\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def write_cropped_image_by_bb(folder_path, frame_num, person_id, img, bb):\n",
    "    cv2.imwrite(folder_path +  \"/frame%dperson%d.jpg\" % (frame_num, person_id), \n",
    "                img[bb[1] : bb[1] + bb[3], bb[0] : bb[0] + bb[2]]);\n",
    "\n",
    "\n",
    "    \n",
    "    # visualizes bbs at a new video\n",
    "    \n",
    "    vidFile = cv2.VideoCapture(input_file)\n",
    "    ret, frame = vidFile.read()\n",
    "    \n",
    "    height, width, layers =  frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    output_video = cv2.VideoWriter(output_file, fourcc, 15.0, (width, height))\n",
    "    \n",
    "    raw_faces, frames = frames \n",
    "    \n",
    "    frames = preprocess_bbs(raw_faces, frames)\n",
    "    \n",
    "    for frame_num in frames:\n",
    "        ret, frame = vidFile.read()     \n",
    "        output_video.write(draw_faces_bbs(frame, frames[frame_num]))\n",
    "    \n",
    "    output_video.release()\n",
    "\n",
    "    \n",
    "\n",
    "def draw_faces_bbs(img, faces_bbs):\n",
    "    \n",
    "    # draw rectangles with labels on img\n",
    "    \n",
    "    for face_id in faces_bbs:\n",
    "        (x,y,w,h) = faces_bbs[face_id]['coords']\n",
    "        cv2.putText(img, str(face_id), (x, y), 1, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "        img = draw_rect(img, scale_bb(x, y, w, h, img.shape[0], img.shape[1], 1))\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_rect(img, bb):\n",
    "    \n",
    "    # just draw a rectangle\n",
    "    \n",
    "    x, y, w, h = bb\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255 ,0), 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def video_to_frames_dict(input_file, frames_num, cell, detector):\n",
    "    \n",
    "    # convert video file to dictionary of frames, ids and bbs\n",
    "    \n",
    "    vidFile = cv2.VideoCapture(input_file)\n",
    "    cur_frame = 0    \n",
    "    frames = {}\n",
    "    \n",
    "    ret = True\n",
    "    \n",
    "    all_frames = [None] * frames_num\n",
    "    while cur_frame < frames_num and ret:\n",
    "        ret, frame = vidFile.read() \n",
    "        all_frames[cur_frame] = frame\n",
    "        if cur_frame%cell == 0:\n",
    "            frames[cur_frame] = get_bbs(frame, detector)\n",
    "        else:\n",
    "            frames[cur_frame] = np.array([])\n",
    "        cur_frame += 1\n",
    "    \n",
    "    return frames, all_frames\n",
    "\n",
    "\n",
    "def save_dict_as_csv(faces_dictionary):\n",
    "    with open('faces.csv', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['frame', 'person_id', 'x', 'y', 'w', 'h'])\n",
    "        for frame_num in faces_dictionary:\n",
    "            for person_id in faces_dictionary[frame_num]:\n",
    "                x, y, w, h = faces_dictionary[frame_num][person_id]['coords']\n",
    "                writer.writerow([frame_num, person_id, x, y, w, h])\n",
    "        \n",
    "\n",
    "def video_to_faces(folder_path, input_video, frames_num, detector):\n",
    "    \n",
    "    raw_faces, frames = video_to_frames_dict(input_video, frames_num, detector)\n",
    "    \n",
    "    faces = preprocess_bbs(raw_faces, frames)\n",
    "    \n",
    "    save_dict_as_csv(faces)\n",
    "    \n",
    "    vidFile = cv2.VideoCapture(input_video)\n",
    "    cur_frame = 0       \n",
    "    ret = 1\n",
    "    \n",
    "    while cur_frame < frames_num and ret:\n",
    "        ret, frame = vidFile.read() \n",
    "        for person_id in faces[cur_frame]:\n",
    "            write_cropped_image_by_bb(folder_path, cur_frame, person_id, frame, faces[cur_frame][person_id]['coords'])\n",
    "        cur_frame += 1\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 2.44 s, total: 2min 14s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def extract_people(video_file, visualize=False, frames_limit=100):\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    if visualize:\n",
    "        write_video(video_file, video_to_frames_dict(video_file, frames_limit, cell=100, detector=face_cascade), 'video_aud_cam.avi')\n",
    "    \n",
    "#     video_to_faces('./faces', video_file, frames_limit, face_cascade)\n",
    "    \n",
    "extract_people('splice1.mp4', True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
