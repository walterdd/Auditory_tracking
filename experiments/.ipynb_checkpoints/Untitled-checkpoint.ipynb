{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "people = []\n",
    "bl_people = []\n",
    "face_coo = []\n",
    "\n",
    "\n",
    "def find_faces_VJ(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.1, 5)\n",
    "    return faces\n",
    "\n",
    "\n",
    "def track_obj(faces, frame):\n",
    "    track_windows = [(x, y, w, h) for (x, y, w, h) in faces]\n",
    "    rois = [frame[y:y + h, x:x + w] for (x, y, w, h) in faces]\n",
    "    hsv_rois = [cv2.cvtColor(roi, cv2.COLOR_BGR2HSV) for roi in rois]\n",
    "    masks = [cv2.inRange(hsv_roi, np.array((0., 51., 89.)), np.array((17., 140., 255.))) for hsv_roi in hsv_rois]\n",
    "    roi_hists = [cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180]) for (hsv_roi, mask) in zip(hsv_rois, masks)]\n",
    "    for i in range(len(roi_hists)):\n",
    "        cv2.normalize(roi_hists[i], roi_hists[i], 0, 255, cv2.NORM_MINMAX)\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    return track_windows, rois, hsv_rois, masks, roi_hists, term_crit\n",
    "\n",
    "\n",
    "def check_size(pts_prev, pts_now, size):\n",
    "    return (cv2.contourArea(pts_now) / cv2.contourArea(pts_prev)) >= size\n",
    "\n",
    "\n",
    "def intersection(pts1, pts2):\n",
    "    # In future\n",
    "    return True\n",
    "\n",
    "\n",
    "def draw_face(frame, faces):\n",
    "    for (x, y, w, h) in faces:\n",
    "        print(1)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    return 0\n",
    "\n",
    "def flow(input_vid, output, frames_limit):\n",
    "    cap = cv2.VideoCapture(input_vid)\n",
    "    \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    ret, frame = cap.read()\n",
    "    height, width, layers =  frame.shape\n",
    "    out = cv2.VideoWriter(output, fourcc, 10.0, (width, height))\n",
    "    current_frame = -1\n",
    "    ret = True\n",
    "    while(ret and current_frame < frames_limit):\n",
    "        ret, frame = cap.read()\n",
    "        current_frame += 1\n",
    "\n",
    "#         if current_frame % 2 == 0: # each 5-th frame\n",
    "        cur_faces = find_faces_VJ(frame)\n",
    "        if current_frame == 0:\n",
    "            faces = cur_faces\n",
    "            for i in range(len(faces)):\n",
    "                people.append([])\n",
    "                face_coo.append([])\n",
    "                bl_people.append(True)\n",
    "            track_windows, rois, hsv_rois, masks, roi_hists, term_crit = track_obj(faces, frame)\n",
    "        \n",
    "        img2 = frame\n",
    "#         out.write(img2)\n",
    "        for i in range(len(people)):\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            dst = cv2.calcBackProject([hsv], [0], roi_hists[i], [0, 180], 1)\n",
    "            \n",
    "            \n",
    "            print dst, track_windows[i], term_crit, \"\\n_____________\"\n",
    "            ret, track_windows[i] = cv2.CamShift(dst, track_windows[i], term_crit)\n",
    "            \n",
    "            \n",
    "            pts = cv2.boxPoints(ret)\n",
    "\n",
    "            pts = np.int0(pts)\n",
    "            people[i] = pts\n",
    "            face_coo[i].append(cv2.contourArea(pts))\n",
    "            if face_coo[i][current_frame] / max(1,face_coo[i][current_frame if current_frame - 5 < 0 else current_frame - 5]) >= 2:\n",
    "                bl_people[i] = False\n",
    "                track_windows[i] = (track_windows[i][0]/2, track_windows[i][1]/2, track_windows[i][2]/2, track_windows[i][3]/2)\n",
    "            img2 = cv2.polylines(frame, [pts], True, 255, 2)\n",
    "            cv2.putText(img2, str(i), (pts[0][0], pts[0][1]), 1, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        out.write(img2)\n",
    "#         print 1\n",
    "\n",
    "    out.release()\n",
    "\n",
    "flow('slice.mp4', 'output.avi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
